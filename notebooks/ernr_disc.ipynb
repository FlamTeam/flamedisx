{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ernr_disc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsz8CE2Qlta2",
        "colab_type": "text"
      },
      "source": [
        "# ER / NR discrimination test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuVS7q57lta8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab = True\n",
        "\n",
        "if colab:\n",
        "    !git clone https://github.com/FlamTeam/flamedisx.git\n",
        "\n",
        "    # Install TF2 and TFP w GPU support (change runtime to GPU to test)\n",
        "    !pip install -U tensorflow-gpu==2.0.0\n",
        "    !pip install -U tensorflow_probability==0.8.0\n",
        "    \n",
        "    %cd flamedisx\n",
        "    !git checkout master\n",
        "    !git pull origin master\n",
        "    !python setup.py develop\n",
        "    %cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAtsuykGltbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "from multihist import Hist1d, Histdd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy import stats, interpolate\n",
        "import pickle\n",
        "\n",
        "import flamedisx\n",
        "import flamedisx as fd\n",
        "from flamedisx.x1t_sr0 import SR0WIMPSource, SR0ERSource, SR0NRSource\n",
        "\n",
        "tf.__version__, tfp.__version__, tf.test.is_gpu_available(), tf.executing_eagerly()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDCTxQM-ltbP",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msxgll3DltbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LowMassWIMPSource(SR0WIMPSource):\n",
        "    mw = 30  # GeV\n",
        "    n_in = 2  # single WIMP spectrum (no modulation)\n",
        "    # Only for 10 GeV WIMP\n",
        "    # es = np.geomspace(0.7, 10, 100) # [keV]\n",
        "    \n",
        "class LowEnergyERSource(SR0ERSource):\n",
        "    def _single_spectrum(self):\n",
        "        \"\"\"Return (energies in keV, rate at these energies),\n",
        "        \"\"\"\n",
        "        return (tf.dtypes.cast(\n",
        "                    tf.linspace(0., 5., 1000),  # 10 keV for 1 TeV WIMP\n",
        "                    dtype=fd.float_type()),\n",
        "                tf.ones(1000, dtype=fd.float_type()))\n",
        "    \n",
        "def annotate_cs(d):\n",
        "    d['cs1'] = (0.142 / (1 + 0.219)) * d['s1'] / (\n",
        "        d['photon_detection_eff'] * d['photon_gain_mean'])\n",
        "    d['cs2'] = (11.4 / (1 - 0.63) / 0.96) * d['s2'] / (\n",
        "        d['electron_detection_eff'] * d['electron_gain_mean'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1yzT0VDnwQNG",
        "colab": {}
      },
      "source": [
        "dsets = dict(\n",
        "    er=dict(source_class=LowEnergyERSource),\n",
        "    nr=dict(source_class=LowMassWIMPSource))\n",
        "\n",
        "for k, v in dsets.items():\n",
        "    dsets[k]['source'] = v['source_class'](batch_size=300, max_sigma=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TO3vDSsEwQNf",
        "colab": {}
      },
      "source": [
        "## Compute rate histograms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1L9n2Ultbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for dname, q in dsets.items():\n",
        "    q['mh'] = mh = Histdd(bins=(\n",
        "        np.linspace(0, 70, 71 + 1),\n",
        "        np.geomspace(10**1.7 / (1 - 0.63),\n",
        "                     10**3.9 / (1 - 0.63), \n",
        "                     70)\n",
        "        #np.linspace(0, 5e3, 70),\n",
        "    ))\n",
        "    \n",
        "    # Actually 40 gives pretty good results already, but let's do it right\n",
        "    n_batches = 100 if dname == 'er' else 40\n",
        "    trials_per_batch = int(1e6)\n",
        "    \n",
        "    for _ in tqdm(range(n_batches)):\n",
        "        d = q['source'].simulate(trials_per_batch)\n",
        "        annotate_cs(d)\n",
        "        mh.add(d['cs1'], d['cs2'])\n",
        "    \n",
        "    # Convert to PDF\n",
        "    mh /= mh.bin_volumes() * trials_per_batch * n_batches\n",
        "\n",
        "    # Multiply by total expected event rate\n",
        "    # (from the source, i.e. before correcting for efficiencies)\n",
        "    mh *= q['source'].mu_before_efficiencies()\n",
        "    q['mh'] = mh\n",
        "\n",
        "    plt.yscale('log')\n",
        "    mh.plot(cblabel='rate * PDF')\n",
        "    plt.xlabel(\"cS1 [PE]\")\n",
        "    plt.ylabel(\"cS2 [PE]\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VG88gt7ltbq",
        "colab_type": "text"
      },
      "source": [
        "  * Make sure none of the models are 'cut off' in cS1 / cS2, since cS1 and cS2 cut acceptances are not currently accounted for in our likelihood (unlike S1 or S2 cuts). This is not a limitation of flamedisx: the correction value is known for each event since the correction depends only on observables, so ultimately a cS1 cut is just a space-dependent S1 cut (which flamedisx fully supports).\n",
        "  * The ROC curves will depend on the extent of the ER spectrum. If you include more high-energy ER events that can be discriminated anyway, the ER leakage in any likelihood will go down. The key figure of merit we are trying to derive here, the decrease in ER leakage at ~50 % NR acceptance when switching to the full likelihood, should be unaffected by this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1xvN-dZltbs",
        "colab_type": "text"
      },
      "source": [
        "Discrimination ROC curve based on the histogram:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v7cFdycfwQNx",
        "colab": {}
      },
      "source": [
        "nr = dsets['nr']['mh'].histogram.ravel()\n",
        "er = dsets['er']['mh'].histogram.ravel()\n",
        "\n",
        "ins = np.argsort(er/(nr + 1e-9))\n",
        "plt.figure()\n",
        "plt.gcf().patch.set_facecolor('white')\n",
        "plt.plot(np.cumsum(er[ins])/er.sum(),\n",
        "         np.cumsum(nr[ins])/nr.sum())\n",
        "plt.xscale('log')\n",
        "\n",
        "plt.axvline(1/800, color='k')\n",
        "\n",
        "plt.xlim(1e-4, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "enwsoRMfWw91",
        "colab": {}
      },
      "source": [
        "## Compute flamedisx differential rates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-HtdsmoQwQN2",
        "colab": {}
      },
      "source": [
        "# Reinitialize source with diference max_sigma or batch_size\n",
        "#for k, v in dsets.items():\n",
        "#    dsets[k]['source'] = v['source_class'](batch_size=100, max_sigma=6)\n",
        "\n",
        "for dname, q in dsets.items():\n",
        "    #ft_test = dict(x=0., y=0., z=-50,)\n",
        "    q['data'] = d = q['source'].simulate(int(1e6))\n",
        "    annotate_cs(d)\n",
        "    \n",
        "    # Ensure cs1 and cs2 are in range of the histogram\n",
        "    # to avoid extrapolation in multihist's lookup.\n",
        "    # NB: we are assuming both histograms have the same binning here!\n",
        "    bes = q['mh'].bin_edges\n",
        "    mask = (\n",
        "        (bes[0][0] < d['cs1']) & (d['cs1'] < bes[0][-1]) &\n",
        "        (bes[1][0] < d['cs2']) & (d['cs2'] < bes[1][-1])\n",
        "    )\n",
        "    print(f\"{dname}: Throwing out {100 * (~mask).sum() / len(d):.2f}% of events\")\n",
        "    q['data'] = d = d[mask].copy()\n",
        "    \n",
        "    for _dn in dsets.keys():\n",
        "        w = dsets[_dn]\n",
        "        w['source'].set_data(d.copy())\n",
        "        d['l_full_' + _dn] = w['source'].batched_differential_rate()\n",
        "        d['l_mh_' + _dn] = w['mh'].lookup(d['cs1'], d['cs2'])\n",
        "        \n",
        "    for lt in ('mh', 'full'):\n",
        "        d['lr_' + lt] = d['l_%s_er' % lt] / d['l_%s_nr' % lt]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI1kB9GjltcT",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5HaaHualtcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load earlier results: \n",
        "#with open('discstudy_22oct_elife452.pkl', mode='rb') as f:\n",
        "#    dsets = pickle.load(f)\n",
        "#     for k, v in q.items():\n",
        "#         dsets[k].update(**v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubzxw4Cjltcf",
        "colab_type": "text"
      },
      "source": [
        "## Compare differential rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NcOSJiWltcg",
        "colab_type": "text"
      },
      "source": [
        "Compare differential rates. There will be an offset because (cS1, cS2) and (S1, S2) have different ranges/means -- so the rates are differential with respect to different coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MT23A5Xltch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for dn in dsets:\n",
        "    for lh_dn in dsets:\n",
        "        q = dsets[dn]['data']\n",
        "        plt.figure()\n",
        "        plt.gcf().patch.set_facecolor('white')\n",
        "        y, x = q['l_full_' + lh_dn], q['l_mh_' + lh_dn]\n",
        "\n",
        "        Histdd(x, y,\n",
        "               bins=(np.geomspace(1e-7, 1e-1, 100),\n",
        "                     np.geomspace(1e-7, 1e-1, 100))).plot(\n",
        "            log_scale=True, cblabel='Events/bin')\n",
        "\n",
        "        plt.plot([1e-7, 1e-1], [1e-7, 1e-1], 'k-')\n",
        "        plt.yscale('log')\n",
        "        plt.xscale('log')\n",
        "        plt.xlabel(\"Histogram\")\n",
        "        plt.ylabel(\"Flamedisx\")\n",
        "        plt.ylim(1e-7, 1e-1)\n",
        "        plt.xlim(1e-7, 1e-1)\n",
        "        plt.title(f\"{dn.upper()} data, {lh_dn.upper()} model\")\n",
        "        plt.gca().set_aspect(1)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99KiYcYJltcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Zoom-in on the low-energy NR data\n",
        "# d = dsets['nr']['data']\n",
        "# dsets['er']['mh'].plot(log_scale=True, vmin=1e-6, vmax=1e-1, cmap=plt.cm.Blues, cblabel=\"Diffrate hist\")\n",
        "# plt.scatter(d['cs1'], d['cs2'], c=d['l_full_er'], s=0.1, \n",
        "#             vmax=1e-1, vmin=1e-6, norm=matplotlib.colors.LogNorm(), cmap=plt.cm.Reds)\n",
        "# plt.colorbar(label='Diffrate Flamedisx')\n",
        "# plt.xlim(0, 10)\n",
        "# plt.xlabel(\"cS1 [PE]\")\n",
        "# plt.ylim(0, 3e3)\n",
        "# plt.ylabel(\"cS2 [PE]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGNYu8vvltct",
        "colab_type": "text"
      },
      "source": [
        "## Compare event-by-event discrimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyaxFw_4ltcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_er = dsets['er']['data']\n",
        "d_nr = dsets['nr']['data']\n",
        "\n",
        "for d, alt, cmap in [#(d_er, d_nr, plt.cm.viridis),\n",
        "                     (d_nr, d_er, plt.cm.magma)\n",
        "                    ]:\n",
        "    # For each event in d, find what fraction of the alt data is more NR-like than it\n",
        "    # (under both likelihoods)\n",
        "    f_above = {\n",
        "        lt: np.searchsorted(np.sort(alt[f'lr_{lt}'].values), \n",
        "                            d[f'lr_{lt}'].values).astype(np.float) / len(alt)\n",
        "        for lt in ('mh', 'full')}\n",
        "\n",
        "    # Get ratio. \n",
        "    #   0 = mh sees the event as more NR-like than any of the alt data\n",
        "    #   > 1: mh is worse at discriminating, < 1 mh is better at discriminating\n",
        "    ratio = f_above['mh'] / f_above['full']\n",
        "    mask = np.isfinite(ratio)\n",
        "    \n",
        "    xkey, ykey = 's1', 'z'\n",
        "    \n",
        "    plt.scatter(d[xkey][mask], d[ykey][mask], c=ratio[mask], #cmap=cmap,\n",
        "                vmin=0, vmax=2, cmap=plt.cm.seismic,\n",
        "                s=0.2,)\n",
        "    plt.colorbar()\n",
        "    plt.scatter(d[xkey][~mask], d[ykey][~mask], c='g',\n",
        "                s=0.2, alpha=0.2)\n",
        "    \n",
        "    plt.xlabel(xkey)\n",
        "    #plt.ylim(0, 700)\n",
        "    plt.ylabel(ykey)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEcKKegvltcz",
        "colab_type": "text"
      },
      "source": [
        "For these NR events, red events have a more NR-like ER/NR likelihood ratio in flamedisx, and blue ones in the histogram likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_9KjxzqawQN9",
        "colab": {}
      },
      "source": [
        "# Saving data for later:\n",
        "#dsets_data = dict()\n",
        "#for dn in ['er', 'nr']:\n",
        "#    dsets_data[dn] = dict()\n",
        "#    for k, v in dsets[dn].items():\n",
        "#        if k in ['source', 'source_class']:\n",
        "#            continue\n",
        "#        print(dn, k, type(v))\n",
        "#        dsets_data[dn][k] = v\n",
        "#\n",
        "#with open('discstudy_23oct_elife452_10GeV_modulation.pkl', mode='wb') as f:\n",
        "#    pickle.dump(dsets_data, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEA9K_-Bltc5",
        "colab_type": "text"
      },
      "source": [
        "Log likelihood ratio histograms for ER and NR data under both likelihoods below. Note many events are at +- 20 due to clip. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dMFJjfQltc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.gcf().patch.set_facecolor('white')\n",
        "for lt, color in [['mh', 'b'], ['full', 'g']]:\n",
        "    hists = dict()\n",
        "    cis = dict()\n",
        "    for dname, q in dsets.items():\n",
        "        exp = 20\n",
        "        hists[dname] = Hist1d(\n",
        "            np.log10(q['data']['lr_' + lt].clip(10**-exp, 10**exp).values.astype('float')),\n",
        "            bins=np.linspace(-7, 7, 140))\n",
        "        hists[dname].plot(label=f\"{dname}{lt}: {hists[dname].n}\")\n",
        "#plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxU8HT6IltdC",
        "colab_type": "text"
      },
      "source": [
        "ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a71MnstbrZ_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binom_interval(success, total, conf_level=0.95):\n",
        "    \"\"\"Confidence interval on binomial - using Jeffreys interval\n",
        "    Code stolen from https://gist.github.com/paulgb/6627336\n",
        "    Agrees with http://statpages.info/confint.html for binom_interval(1, 10)\n",
        "    \"\"\"\n",
        "    # TODO: special case for success = 0 or = total? see wikipedia\n",
        "    quantile = (1 - conf_level) / 2.\n",
        "    lower = stats.beta.ppf(quantile, success, total - success + 1)\n",
        "    upper = stats.beta.ppf(1 - quantile, success + 1, total - success)\n",
        "    \n",
        "    # If something went wrong with a limit calculation, report the trivial limit\n",
        "    lower[np.isnan(lower)] = 0\n",
        "    upper[np.isnan(upper)] = 1\n",
        "    return lower, upper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzx75j8PltdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_roc(dsets):\n",
        "    results = dict()\n",
        "    plt.figure()\n",
        "    plt.gcf().patch.set_facecolor('white')\n",
        "    for lt, color in [['mh', 'b'], ['full', 'g']]:\n",
        "        hists = dict()\n",
        "        cis = dict()\n",
        "        for dname, q in dsets.items():\n",
        "            hists[dname] = Hist1d(np.log10(q['data']['lr_' + lt].clip(1e-20, 1e20)),\n",
        "                                bins=np.linspace(-21, 21, 10000))\n",
        "            \n",
        "            cis[dname] = binom_interval(\n",
        "                np.cumsum(hists['er'].histogram),\n",
        "                hists['er'].n, \n",
        "                conf_level=.68)\n",
        "            \n",
        "        x = np.cumsum(hists['er'].normalized_histogram)\n",
        "        xlow, xhigh = cis['er'][0], cis['er'][1]\n",
        "        y = np.cumsum(hists['nr'].normalized_histogram)\n",
        "        \n",
        "        results[lt] = dict(x=x, y=y, cis=cis, xlow=xlow, xhigh=xhigh, hists=hists)\n",
        "        \n",
        "        plt.plot(x, y,\n",
        "                label=dict(mh=\"Classical (cS1, cS2)\", \n",
        "                            full=\"Full (S1, S2, x, y, z, t)\")[lt],\n",
        "                color=color)\n",
        "        \n",
        "        print(\"%s: %0.3g ER bg. at 50%% NR acceptance\" % (\n",
        "            lt, x[np.argmin(np.abs(y - 0.5))]\n",
        "        ))\n",
        "        \n",
        "        plt.fill_betweenx(\n",
        "            y, cis['er'][0], cis['er'][1],\n",
        "            color=color, alpha=0.2, linewidth=0, step='mid')\n",
        "\n",
        "    plt.legend(loc='lower right', frameon=False, fontsize=12)\n",
        "        \n",
        "    plt.xscale('log')\n",
        "    plt.xlabel(\"ER (flat 0-5 keV) background\")\n",
        "    plt.ylabel(f\"{mw} GeV/c^2 WIMP acceptance\")\n",
        "    #plt.xlim(1e-4, 1e-1)\n",
        "    #plt.xlim(0, 1)\n",
        "    #plt.ylim(0.95, 1)\n",
        "    plt.tight_layout()\n",
        "    #plt.savefig('ernr_disc_comp_varelife.png', bbox_inches=\"tight\", dpi=200)\n",
        "    plt.show()\n",
        "\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51sHV1My_akw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Single dataset\n",
        "mw = 10  # GeV WIMP mass\n",
        "all_results = dict()\n",
        "all_results[''] = make_roc(dsets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2pbGB1As76K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Or load several datasets to compare\n",
        "basename = 'discstudy_23oct_elife452_10GeV'\n",
        "#postfix = ['', '_spatial', '_spatial_temp']\n",
        "postfix = ['', '_modulation']\n",
        "\n",
        "mw = 10  # GeV WIMP mass\n",
        "all_results = dict()\n",
        "\n",
        "for v in postfix:\n",
        "    with open(basename + v + '.pkl', mode='rb') as f:\n",
        "        q = pickle.load(f)\n",
        "        # Make and store ROC curves\n",
        "        all_results[v] = make_roc(q)\n",
        "\n",
        "# Sanity check, are all mh rocs the same?\n",
        "for v in all_results.values():\n",
        "    plt.plot(v['mh']['x'], v['mh']['y'])\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title('Ensure these distributions are the same within errors')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zRNwB0xtOBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "for (k, k2, label, color) in [('', 'mh', 'Classical (cS1, cS2)', None),\n",
        "                              ('', 'full', 'Full (S1, S2, x, y, z, t)', 'orange'),\n",
        "                              ('_modulation', 'full', 'Full + modulation', 'green'),\n",
        "                              #('_spatial', 'full', 'Full + spatial rate', 'green'),\n",
        "                              #('_spatial_temp', 'full', 'Full + spatial + temporal rate', 'r'),\n",
        "                              ]:\n",
        "    q = all_results[k][k2]\n",
        "\n",
        "    plt.plot(q['x'], q['y'], label=label, color=color)\n",
        "    \n",
        "    print(\"%s: %0.3g ER bg. at 50%% NR acceptance\" % (\n",
        "        label, q['x'][np.argmin(np.abs(q['y'] - 0.5))]\n",
        "    ))\n",
        "    \n",
        "    plt.fill_betweenx(\n",
        "        q['y'], q['cis']['er'][0], q['cis']['er'][1],\n",
        "        color=color, alpha=0.2, linewidth=0, step='mid')\n",
        "\n",
        "plt.legend(loc='lower right', frameon=False, fontsize=12)\n",
        "    \n",
        "plt.xscale('log')\n",
        "plt.xlabel(\"ER (flat 0-5 keV) background\")\n",
        "plt.ylabel(f\"{mw} GeV/c^2 WIMP acceptance\")\n",
        "plt.xlim(1e-6, 1)\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.savefig('ernr_disc_comp_varelife_10GeV_modulation.png', bbox_inches=\"tight\", dpi=200)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3kmLhugltdL",
        "colab_type": "text"
      },
      "source": [
        "Background reduction plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSlrdZDuyEFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = dict()\n",
        "results['mh'] = all_results['']['mh']\n",
        "results['full'] = all_results['']['full']\n",
        "results['modulation'] = all_results['_modulation']['full']\n",
        "#results['spatial'] = all_results['_spatial']['full']\n",
        "#results['time'] = all_results['_spatial_temp']['full']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14CXWQJv1lG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduction_fraction(a, b):\n",
        "    # background reduction fractions\n",
        "    ys = (a['']-b[''])/a['']\n",
        "    \n",
        "    errs = dict()\n",
        "    for (v, sign) in [('high', 1), ('low', -1)]:\n",
        "        # f = a*A - b*B\n",
        "        # sigmaf = a**2 * sigmaA**2 + b**2 * sigmaB**2   ## no A B correlation\n",
        "        f = a[''] - b['']\n",
        "        sf_sq = (a[v] - a[''])**2 + (b[v] - b[''])**2\n",
        "\n",
        "        # add rel err\n",
        "        err = (sf_sq/f**2 + (a[v] - a[''])**2/a['']**2) * ys**2\n",
        "        \n",
        "        # rel err y\n",
        "        errs[v] = ys * 100 + sign * (err * 100**2)**0.5\n",
        "    # mask nans\n",
        "    errs['high'][np.isnan(errs['high'])] = 100.\n",
        "    errs['low'][np.isnan(errs['low'])] = 0.\n",
        "    return ys, errs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCm1T2S_ltdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, axes = plt.subplots(2, 1, \n",
        "                       figsize=(5, 5), \n",
        "                       gridspec_kw = {'height_ratios': [2, 1]},\n",
        "                       sharex=True)\n",
        "plt.gcf().patch.set_facecolor('white')\n",
        "\n",
        "xscale = 100\n",
        "\n",
        "for lt, color in [['mh', None],\n",
        "                  ['full', 'orange'],\n",
        "                  ['modulation', 'green'],\n",
        "                  #['spatial', 'green'],\n",
        "                  #['time', 'red'],\n",
        "                  ]:\n",
        "    q = results[lt]\n",
        "    \n",
        "    plt.sca(axes[0])\n",
        "    plt.plot(q['y'] * xscale, q['x'],\n",
        "             label=dict(mh=\"Classical (cS1, cS2)\", \n",
        "                        full=\"Full (S1, S2, x, y, z, t)\",\n",
        "                        spatial=\"Full + spatial rate\",\n",
        "                        time=\"Full + spatial + temporal rate\",\n",
        "                        modulation=\"Full + modulation\",\n",
        "                        )[lt],\n",
        "             color=color)\n",
        "    plt.fill_between(\n",
        "        q['y'] * xscale, q['xlow'], q['xhigh'],\n",
        "        color=color, alpha=0.2, lw=0)\n",
        "    \n",
        "def itp(x, xp, yp):\n",
        "    return interpolate.interp1d(xp, yp, \n",
        "                                bounds_error=False, fill_value=(0,1))(x)\n",
        "    \n",
        "plt.sca(axes[1])\n",
        "pts = np.linspace(0, 1, 1000)\n",
        "r = {\n",
        "    lt: {\n",
        "        q: itp(pts, results[lt]['y'], results[lt]['x' + q])\n",
        "          for q in ['', 'low', 'high']}\n",
        "    for lt in results.keys()\n",
        "}\n",
        "\n",
        "for (bgf, label, color) in [('full', 'Classical vs Full', 'k'),\n",
        "                            ('modulation', 'Classical vs Full + modulation', 'g'),\n",
        "                            #('spatial', 'Classical vs Full + spatial', 'g'),\n",
        "                            #('time', 'Classical vs Full + spatial + time', 'r'),\n",
        "                            ]:\n",
        "    ys, errs = reduction_fraction(r['mh'], r[bgf])\n",
        "\n",
        "    plt.plot(pts * xscale, \n",
        "             100 * ys, c=color, label=label)\n",
        "\n",
        "    plt.fill_between(pts * xscale,\n",
        "                     errs['low'],\n",
        "                     errs['high'], color=color, alpha=0.2, lw=0,\n",
        "                     )\n",
        "\n",
        "plt.legend(frameon=False)\n",
        "plt.ylabel(\"Bg. reduction (%)\")\n",
        "plt.ylim(0, 100)\n",
        "plt.xlim(0, 100)\n",
        "plt.xlabel(\"%d GeV/c^2 WIMP acceptance (%%)\" % mw)\n",
        "\n",
        "    \n",
        "plt.sca(axes[0])\n",
        "plt.yscale('log')\n",
        "plt.ylim(1.1e-6, 1)\n",
        "plt.legend(loc='upper left', frameon=False)\n",
        "plt.ylabel(\"ER (1-5 keV) bg. fraction\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(hspace=0)\n",
        "plt.savefig('ernr_disc_comp_10GeV_modulation.png', bbox_inches=\"tight\", dpi=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SCJsaeKYrPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}